---
title: 為什麼需要 Observability？從 Log 開始的監控之旅
description: 理解 Observability 的核心概念，以及為什麼 Log 是系統監控的基礎
date: 2025-12-01
slug: observability-000-intro
series: "observability"
tags:
  - "observability"
  - "logging"
---

## 情境：凌晨三點的電話

想像一下這個場景：凌晨三點，你被一通電話吵醒。客服告訴你：「使用者反映系統很慢，有些人根本登不進去。」

你睡眼惺忪地打開電腦，開始排查問題：

- 是網路問題嗎？
- 是資料庫連線滿了嗎？
- 是某個 **API**（Application Programming Interface，程式間溝通的介面）掛掉了嗎？
- 還是記憶體不足導致 **OOM**（Out of Memory，記憶體耗盡導致程式被強制終止）？

### 沒有 Observability 的情況

如果你的系統沒有任何監控機制，你只能：

1. 用 **SSH**（Secure Shell，遠端連線工具）登入每台伺服器
2. 到處翻找散落各處的 log 檔案
3. 用 `grep` 指令搜尋關鍵字，猜測問題在哪裡
4. 這個過程可能需要**數小時**，而使用者持續受到影響

### 有 Observability 的情況

如果你有完善的監控系統，同樣的情境會變成這樣：

1. **你在電話響之前就收到告警**：系統自動偵測到錯誤率上升，發送通知
2. **打開 Dashboard 就看到問題**：圖表顯示 `auth-service` 的錯誤率在 10 分鐘前開始飆升
3. **一鍵查看相關 log**：搜尋 `auth-service` 最近的 error log，發現「資料庫連線逾時」
4. **定位根本原因**：查看資料庫的 metrics，發現連線數已達上限
5. **解決時間：15 分鐘**，而不是數小時

這就是為什麼我們需要 **Observability**（可觀測性）。

## 什麼是 Observability？

**Observability**（可觀測性）是指透過系統產生的外部輸出，來理解系統內部狀態的能力。

簡單來說：當系統出問題時，你能多快找到問題在哪裡、為什麼發生？

一個具備良好 Observability 的系統，應該能讓你：

1. **快速發現問題** — 系統異常時主動通知你，而不是等使用者回報
2. **快速定位問題** — 從症狀追溯到根本原因，而不是盲目猜測
3. **理解系統行為** — 知道正常狀態長什麼樣子，才能辨識異常

## Observability 三支柱

業界通常把 Observability 分為三個核心支柱：

| 支柱 | 說明 | 回答的問題 |
|------|------|-----------|
| **Logs**（日誌） | 系統運行時產生的事件記錄 | 「發生了什麼事？」 |
| **Metrics**（指標） | 隨時間變化的數值測量 | 「系統狀態如何？」 |
| **Traces**（追蹤） | 請求在分散式系統中的完整路徑 | 「請求經過了哪些服務？」 |

### Logs（日誌）

**Log** 是系統運行時產生的離散事件記錄。每一條 log 通常包含：

- 時間戳記（when）
- 事件來源（where）
- 嚴重程度（level）
- 訊息內容（what）

```
2024-06-01T12:00:00Z [ERROR] auth-service: Failed to connect to database: connection refused
```

Log 的優點是**細節豐富**，可以記錄任何你想知道的資訊。缺點是資料量大，需要有效的收集和查詢機制。

### Metrics（指標）

**Metric** 是隨時間變化的數值測量，例如：

- CPU 使用率：85%
- 記憶體使用量：12GB
- API 請求延遲：**p99** = 200ms
- 錯誤率：0.5%

:::info
**什麼是 p99？**

p99（第 99 百分位數）表示「99% 的請求都比這個值快」。如果 p99 = 200ms，代表 100 個請求中有 99 個在 200ms 內完成，只有最慢的 1% 超過 200ms。

為什麼不用平均值？因為平均值會被極端值影響。假設 99 個請求花 10ms，1 個請求花 10 秒，平均值是 109ms，看起來還可以。但 p99 會告訴你「有些請求真的很慢」。
:::

Metrics 的優點是**可量化、可聚合**（例如計算平均值、加總、比較趨勢），適合用來設定告警閾值和觀察趨勢。缺點是只有數字，缺乏細節——你知道錯誤率上升了，但不知道是什麼錯誤。

### Traces（追蹤）

**Trace** 記錄一個請求在**分散式系統**中的完整路徑。

:::info
**什麼是分散式系統？**

早期的應用程式是「單體式」：所有功能都在同一個程式裡。現代系統為了擴展性和維護性，常拆分成多個獨立的「服務」，各自負責不同功能（例如：登入服務、訂單服務、付款服務）。這些服務可能跑在不同的機器上，透過網路互相溝通——這就是分散式系統。
:::

例如一個「查看用戶資料」的請求可能經過：

```
瀏覽器 → API Gateway（入口閘道）→ Auth Service（驗證身份）→ User Service（取得資料）→ Database（資料庫）
```

Trace 的優點是能看到**請求的完整生命週期**，定位哪個環節最慢或出錯。缺點是需要在程式碼中加入追蹤邏輯，實作成本較高。

## 為什麼從 Log 開始？

這個系列選擇從 **Log** 開始，原因有幾個：

1. **Log 是最基礎的** — 幾乎所有系統都會產生 log，不需要額外「埋點」（在程式碼中加入追蹤邏輯）
2. **Log 的細節最豐富** — 當 metrics 告訴你「錯誤率上升」，log 能告訴你「發生了什麼錯誤」
3. **Log 是診斷的最後一哩路** — 即使有完善的 metrics 和 traces，最終還是需要看 log 來確認細節（例如：完整的錯誤訊息、堆疊追蹤）
4. **學習曲線較平緩** — 不需要修改程式碼，只需要收集現有的 log

## Log 管理的挑戰

當系統規模成長，Log 管理會面臨幾個挑戰：

### 1. Log 分散在各處

- Web server 的 log 在 `/var/log/nginx/`
- Application 的 log 在 `/var/log/app/`
- Database 的 log 在另一個路徑
- 每台機器都有自己的 log

排查問題時，你需要 SSH 進多台機器、用 `grep` 搜尋、手動關聯時間戳記。

### 2. Log 格式不一致

```
# Nginx access log
192.168.1.1 - - [01/Jun/2024:12:00:00 +0000] "GET /api/users HTTP/1.1" 200 1234

# Application log
2024-06-01T12:00:00Z [INFO] UserController: Fetched 10 users

# Syslog
Jun  1 12:00:00 server1 sshd[12345]: Accepted publickey for user from 192.168.1.1
```

每種 log 格式都不同，很難統一查詢和分析。

### 3. Log 量太大

一個中等規模的系統，每天可能產生數 GB 到數 TB 的 log。用 `grep` 搜尋不僅慢，而且不切實際。

### 4. Log 沒有保留

預設情況下，log 檔案會隨著 **log rotation** 被刪除。

:::info
**什麼是 Log Rotation？**

Log 檔案會不斷增長，如果放任不管會把磁碟塞滿。Log rotation 是一種自動化機制：當 log 檔案達到一定大小或時間後，系統會將舊的 log 壓縮或刪除，只保留最近幾天/幾週的資料。

這是必要的管理措施，但也意味著：當你想查上週的問題時，log 可能已經不見了。
:::

## 解決方案：集中式 Log 管理

為了解決這些挑戰，我們需要一個 **集中式 Log 管理系統**：

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  Web Server │     │  App Server │     │  Database   │
│    logs     │     │    logs     │     │    logs     │
└──────┬──────┘     └──────┬──────┘     └──────┬──────┘
       │                   │                   │
       └───────────────────┼───────────────────┘
                           │
                           ▼
                   ┌───────────────┐
                   │  Log Shipper  │  ← 收集、解析、轉換
                   │   (Vector)    │
                   └───────┬───────┘
                           │
                           ▼
                   ┌───────────────┐
                   │  Log Storage  │  ← 儲存、索引
                   │  (OpenSearch) │
                   └───────┬───────┘
                           │
                           ▼
                   ┌───────────────┐
                   │   Dashboard   │  ← 查詢、視覺化
                   │  (OpenSearch  │
                   │   Dashboards) │
                   └───────────────┘
```

這個架構包含三個核心元件：

1. **Log Shipper**（收集器）— 從各個來源收集 log、解析格式、轉發到儲存系統
2. **Log Storage**（儲存）— 儲存 log 並建立**索引**，支援快速查詢
3. **Dashboard**（儀表板）— 提供查詢介面和視覺化

:::info
**什麼是索引？**

索引（Index）類似書本後面的「關鍵字索引」：你想找「Kubernetes」這個詞出現在哪些頁面，不需要從頭翻到尾，只要查索引就知道「第 23, 45, 67 頁有提到」。

Log 儲存系統會對每條 log 建立索引，讓你能在數百 GB 的資料中**秒速**找到包含特定關鍵字的 log，而不是像 `grep` 一樣逐行掃描。
:::

## 這個系列會學到什麼？

這個 Observability 系列會帶你從零開始建立一個完整的 Log 管理系統：

| 篇章 | 主題 | 你會學到 |
|------|------|---------|
| **001** | Log Pipeline 架構 | 理解各元件的角色、工具選型比較 |
| **002** | OpenSearch 快速上手 | 用 Docker 快速體驗 OpenSearch |
| **003** | Document 與 Index | 理解 OpenSearch 的資料模型 |
| **004** | Analyzer 與 Mapping | 控制資料如何被索引和搜尋 |
| **005** | Vector 實戰 | 收集和轉換 syslog、nginx log |
| **006** | 整合實戰 | 建立完整的 Vector → OpenSearch pipeline |
| **007** | 生產環境架構 | HA、TLS、容量規劃、備份策略 |

## 小結

- **Observability** 是透過系統輸出理解系統內部狀態的能力
- Observability 三支柱：**Logs**、**Metrics**、**Traces**
- **Log** 是最基礎的監控資料，記錄系統發生的事件
- 集中式 Log 管理解決了 log 分散、格式不一、查詢困難的問題
- 這個系列會帶你建立一個基於 **Vector + OpenSearch** 的 Log 管理系統

下一篇，我們會介紹 Log Pipeline 的架構，以及如何選擇適合的工具。
